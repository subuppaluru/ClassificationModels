{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Concepts.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdfpy0yhvMxE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Binary Classification for Machine Learning\n",
        "\n",
        "A binary classification refers to those tasks which can give either of any two class labels as the output. Generally, one is considered as the normal state and the other is considered to be the abnormal state.  The following examples will help you to understand them better.\n",
        "\n",
        "Email Spam detection: Normal State – Not Spam, Abnormal State – Spam\n",
        "\n",
        "Conversion prediction: Normal State – Not churned, Abnormal State – Churn\n",
        "\n",
        "\n",
        "Conversion Prediction: Normal State – Bought an item, Abnormal State – Not bought an item\n",
        "\n",
        "\n",
        "The most popular algorithms which are used for binary classification are :\n",
        "\n",
        "**K-Nearest Neighbours**\n",
        "\n",
        "**Logistic Regression**\n",
        "\n",
        "**Support Vector Machine**\n",
        "\n",
        "**Decision Trees**\n",
        "\n",
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "_JO_2Mv8vNrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-Class Classification\n",
        "\n",
        "These types of classification problems have no fixed two labels but can have any number of labels. Some popular examples of multi-class classification are :\n",
        "\n",
        "**Plant Species Classification**\n",
        "\n",
        "**Face Classification**\n",
        "\n",
        "**Optical Character recognition**\n",
        "\n",
        "\n",
        "The most common algorithms which are used for Multi-Class Classification are :\n",
        "\n",
        "**K-Nearest Neighbours**\n",
        "\n",
        "**Naive Bayes**\n",
        "\n",
        "**Decision trees**\n",
        "\n",
        "**Gradient Boosting**\n",
        "\n",
        "**Random Forest**\n",
        "\n",
        "\n",
        "**One Vs Rest** – The main task here is to fit one model for each class which will be versus all the other classes\n",
        "\n",
        "**One Vs One** – The main task here is to define a binary model for every pair of classes."
      ],
      "metadata": {
        "id": "_EZZqSqjvwyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-Label Classification for Machine Learning\n",
        "\n",
        "In multi-label Classification, we refer to those specific classification tasks where we need to assign two or more specific class labels that could be predicted for each example. A basic example can be photo classification where a single photo can have multiple objects in it like a dog or an apple and etcetera. The main difference is the ability to predict multiple labels and not just one.\n",
        "\n",
        "You cannot use a binary classification model or a multi-class classification model for multi-label classification and you have to use a modified version of the algorithm to incorporate for multiple classes which can be possible and then to look for them all. It becomes more challenging than a simple yes or no statement. The common algorithms used here are :\n",
        "\n",
        "**Multi-label Random Forests**\n",
        "\n",
        "**Multi-label Decision trees**\n",
        "\n",
        "**Multi-label Gradient Boosting**"
      ],
      "metadata": {
        "id": "QWK8ZNVbwZlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imbalanced Classification for Machine Learning\n",
        "\n",
        "An Imbalanced Classification refers to those tasks where the number of examples in each of the classes are unequally distributed. Generally, imbalanced classification tasks are binary classification jobs where a major portion of the training dataset is of the normal class type and a minority of them belong to the abnormal class.\n",
        "\n",
        "The most important examples of these use cases are :\n",
        "\n",
        "**Fraud Detection**\n",
        "\n",
        "**Outlier Detection**\n",
        "\n",
        "**Medical Diagnosis Test**\n",
        "\n",
        "\n",
        "The problems are transformed into binary classification tasks with some specialized techniques. You can either utilise undersampling for the majority classes or oversampling for the minority classes. The most prominent examples are :\n",
        "\n",
        "**Random Undersampling**\n",
        "\n",
        "**SMOTE Oversampling**\n",
        "\n",
        "\n",
        "Special modelling algorithms can be used to give more attention to the minority class when the model is being fitted on the training dataset which includes cost-sensitive machine learning models. Especially for cases like :\n",
        "\n",
        "**Cost-Sensitive Logistic Regression**\n",
        "\n",
        "**Cost-Sensitive Decision Trees**\n",
        "\n",
        "**Cost-Sensitive Support Vector Machines**"
      ],
      "metadata": {
        "id": "bDA1GHsMw953"
      }
    }
  ]
}