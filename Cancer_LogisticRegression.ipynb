{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer_LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MhDmwtLn6jrM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data"
      ],
      "metadata": {
        "id": "S3vAUkbM6vRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer = pd.read_csv('cancer.csv')"
      ],
      "metadata": {
        "id": "GsqzfW5J6v67"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "VJoDkA-C6zKS",
        "outputId": "86bacae0-f9ec-4fc0-f373-398883a79cfe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0d17d449-6451-4d63-8669-016f63ef1875\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d17d449-6451-4d63-8669-016f63ef1875')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d17d449-6451-4d63-8669-016f63ef1875 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d17d449-6451-4d63-8669-016f63ef1875');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      V1     V2      V3      V4  ...     V28     V29      V30  Class\n",
              "0  17.99  10.38  122.80  1001.0  ...  0.2654  0.4601  0.11890      2\n",
              "1  20.57  17.77  132.90  1326.0  ...  0.1860  0.2750  0.08902      2\n",
              "2  19.69  21.25  130.00  1203.0  ...  0.2430  0.3613  0.08758      2\n",
              "3  11.42  20.38   77.58   386.1  ...  0.2575  0.6638  0.17300      2\n",
              "4  20.29  14.34  135.10  1297.0  ...  0.1625  0.2364  0.07678      2\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFH8lByE63Aq",
        "outputId": "867f3136-0706-497b-dcbb-9c13927565ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   V1      569 non-null    float64\n",
            " 1   V2      569 non-null    float64\n",
            " 2   V3      569 non-null    float64\n",
            " 3   V4      569 non-null    float64\n",
            " 4   V5      569 non-null    float64\n",
            " 5   V6      569 non-null    float64\n",
            " 6   V7      569 non-null    float64\n",
            " 7   V8      569 non-null    float64\n",
            " 8   V9      569 non-null    float64\n",
            " 9   V10     569 non-null    float64\n",
            " 10  V11     569 non-null    float64\n",
            " 11  V12     569 non-null    float64\n",
            " 12  V13     569 non-null    float64\n",
            " 13  V14     569 non-null    float64\n",
            " 14  V15     569 non-null    float64\n",
            " 15  V16     569 non-null    float64\n",
            " 16  V17     569 non-null    float64\n",
            " 17  V18     569 non-null    float64\n",
            " 18  V19     569 non-null    float64\n",
            " 19  V20     569 non-null    float64\n",
            " 20  V21     569 non-null    float64\n",
            " 21  V22     569 non-null    float64\n",
            " 22  V23     569 non-null    float64\n",
            " 23  V24     569 non-null    float64\n",
            " 24  V25     569 non-null    float64\n",
            " 25  V26     569 non-null    float64\n",
            " 26  V27     569 non-null    float64\n",
            " 27  V28     569 non-null    float64\n",
            " 28  V29     569 non-null    float64\n",
            " 29  V30     569 non-null    float64\n",
            " 30  Class   569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq_OxZF066OH",
        "outputId": "8cf8266c-c4bb-44c1-f292-f1ab911d5626"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "2    212\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = cancer.drop(['Class'],axis=1)"
      ],
      "metadata": {
        "id": "K_yX793Z68-W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = cancer['Class']"
      ],
      "metadata": {
        "id": "ebCikd9H6_Z9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train And Test Splitting"
      ],
      "metadata": {
        "id": "qLJibxrR7CPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clp6a4GN7C-u",
        "outputId": "51f8b6a7-991c-40cd-ec3b-7d057a75fb86"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 30) (114, 30) (455,) (114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "ysIjJ7Ac7K4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb1vEDAU7N4s",
        "outputId": "cc638d8d-5ddc-4025-c896-854811b846c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "y_train_pred = logreg.predict(X_train)\n",
        "\n",
        "print(\"Metrics on Train samples\")\n",
        "print(\"============================================================== \")\n",
        "print(\"confusion_matrix: \\n\",confusion_matrix(y_train,y_train_pred))\n",
        "print(\"classification_report: \\n\",classification_report(y_train,y_train_pred))\n",
        "print(\"============================================================== \")\n",
        "\n",
        "y_test_pred = logreg.predict(X_test)\n",
        "\n",
        "print(\"Metrics on Test samples \")\n",
        "print(\"============================================================== \")\n",
        "print(\"confusion_matrix: \\n\",confusion_matrix(y_test,y_test_pred))\n",
        "print(\"classification_report: \\n\",classification_report(y_test,y_test_pred))\n",
        "print(\"============================================================== \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooU05BER7WqG",
        "outputId": "6f793892-188a-48ce-a950-c8f34138b992"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[278   8]\n",
            " [ 15 154]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.97      0.96       286\n",
            "           2       0.95      0.91      0.93       169\n",
            "\n",
            "    accuracy                           0.95       455\n",
            "   macro avg       0.95      0.94      0.95       455\n",
            "weighted avg       0.95      0.95      0.95       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[70  1]\n",
            " [ 3 40]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.99      0.97        71\n",
            "           2       0.98      0.93      0.95        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "============================================================== \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix\n",
        "\n",
        "class_names=[0,1] # name  of classes\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "q89NGUcG8J8-",
        "outputId": "73532276-2535-4405-c798-357b5cd348e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 257.44, 'Predicted label')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n10bdRH988U8",
        "outputId": "90ead9b7-296a-4aac-a642-74c3f0f87114"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "Precision: 0.958904109589041\n",
            "Recall: 0.9859154929577465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression with PCA"
      ],
      "metadata": {
        "id": "JhLpuRzYLUOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Kernel PCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "kpca = KernelPCA(n_components = 2, kernel = 'rbf')\n",
        "X_train = kpca.fit_transform(X_train)\n",
        "X_test = kpca.transform(X_test)"
      ],
      "metadata": {
        "id": "p4lpy5mbLVOg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK3NyCwILaEw",
        "outputId": "ab45f23e-9b9d-499c-852c-18b4b2d55da6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_train_pred = classifier.predict(X_train)\n",
        "\n",
        "print(\"Metrics on Train samples\")\n",
        "print(\"============================================================== \")\n",
        "print(\"confusion_matrix: \\n\",confusion_matrix(y_train,y_train_pred))\n",
        "print(\"classification_report: \\n\",classification_report(y_train,y_train_pred))\n",
        "print(\"============================================================== \")\n",
        "\n",
        "y_test_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Metrics on Test samples \")\n",
        "print(\"============================================================== \")\n",
        "print(\"confusion_matrix: \\n\",confusion_matrix(y_test,y_test_pred))\n",
        "print(\"classification_report: \\n\",classification_report(y_test,y_test_pred))\n",
        "print(\"============================================================== \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-njQ-goTLdrP",
        "outputId": "03cb0844-6261-463e-b766-ee33b8bd42b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [169   0]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      1.00      0.77       286\n",
            "           2       0.00      0.00      0.00       169\n",
            "\n",
            "    accuracy                           0.63       455\n",
            "   macro avg       0.31      0.50      0.39       455\n",
            "weighted avg       0.40      0.63      0.49       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[71  0]\n",
            " [43  0]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.62      1.00      0.77        71\n",
            "           2       0.00      0.00      0.00        43\n",
            "\n",
            "    accuracy                           0.62       114\n",
            "   macro avg       0.31      0.50      0.38       114\n",
            "weighted avg       0.39      0.62      0.48       114\n",
            "\n",
            "============================================================== \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression with LDA"
      ],
      "metadata": {
        "id": "goy9NJLqLnZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "lda = LDA(n_components = 1)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)"
      ],
      "metadata": {
        "id": "FoGs4n3gLoKI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIAqufQpLs4q",
        "outputId": "46a93433-d92c-418f-bb0f-3354e283f228"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_train_pred = classifier.predict(X_train)\n",
        "\n",
        "print(\"Metrics on Train samples\")\n",
        "print(\"============================================================== \")\n",
        "print(\"confusion_matrix: \\n\",confusion_matrix(y_train,y_train_pred))\n",
        "print(\"classification_report: \\n\",classification_report(y_train,y_train_pred))\n",
        "print(\"============================================================== \")\n",
        "\n",
        "y_test_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Metrics on Test samples \")\n",
        "print(\"============================================================== \")\n",
        "print(\"confusion_matrix: \\n\",confusion_matrix(y_test,y_test_pred))\n",
        "print(\"classification_report: \\n\",classification_report(y_test,y_test_pred))\n",
        "print(\"============================================================== \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM9qbUlgLw5S",
        "outputId": "95e9db1f-8408-4a8c-d659-cea25791edab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [169   0]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      1.00      0.77       286\n",
            "           2       0.00      0.00      0.00       169\n",
            "\n",
            "    accuracy                           0.63       455\n",
            "   macro avg       0.31      0.50      0.39       455\n",
            "weighted avg       0.40      0.63      0.49       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[71  0]\n",
            " [43  0]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.62      1.00      0.77        71\n",
            "           2       0.00      0.00      0.00        43\n",
            "\n",
            "    accuracy                           0.62       114\n",
            "   macro avg       0.31      0.50      0.38       114\n",
            "weighted avg       0.39      0.62      0.48       114\n",
            "\n",
            "============================================================== \n"
          ]
        }
      ]
    }
  ]
}