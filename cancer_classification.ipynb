{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cancer_classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac2N2k4T-J7d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data"
      ],
      "metadata": {
        "id": "gaPshVHdhfnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer = pd.read_csv('cancer.csv')"
      ],
      "metadata": {
        "id": "ONE48buXhUZF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "OlBY6BOdgxN2",
        "outputId": "075f45fd-8932-44d3-fa81-1e41ba036dc1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8d642d4a-2000-4de9-b041-5baec31014dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d642d4a-2000-4de9-b041-5baec31014dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d642d4a-2000-4de9-b041-5baec31014dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d642d4a-2000-4de9-b041-5baec31014dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      V1     V2      V3      V4  ...     V28     V29      V30  Class\n",
              "0  17.99  10.38  122.80  1001.0  ...  0.2654  0.4601  0.11890      2\n",
              "1  20.57  17.77  132.90  1326.0  ...  0.1860  0.2750  0.08902      2\n",
              "2  19.69  21.25  130.00  1203.0  ...  0.2430  0.3613  0.08758      2\n",
              "3  11.42  20.38   77.58   386.1  ...  0.2575  0.6638  0.17300      2\n",
              "4  20.29  14.34  135.10  1297.0  ...  0.1625  0.2364  0.07678      2\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n0--s8fgwQV",
        "outputId": "598815e0-2ee3-40f6-8618-901e600c04a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   V1      569 non-null    float64\n",
            " 1   V2      569 non-null    float64\n",
            " 2   V3      569 non-null    float64\n",
            " 3   V4      569 non-null    float64\n",
            " 4   V5      569 non-null    float64\n",
            " 5   V6      569 non-null    float64\n",
            " 6   V7      569 non-null    float64\n",
            " 7   V8      569 non-null    float64\n",
            " 8   V9      569 non-null    float64\n",
            " 9   V10     569 non-null    float64\n",
            " 10  V11     569 non-null    float64\n",
            " 11  V12     569 non-null    float64\n",
            " 12  V13     569 non-null    float64\n",
            " 13  V14     569 non-null    float64\n",
            " 14  V15     569 non-null    float64\n",
            " 15  V16     569 non-null    float64\n",
            " 16  V17     569 non-null    float64\n",
            " 17  V18     569 non-null    float64\n",
            " 18  V19     569 non-null    float64\n",
            " 19  V20     569 non-null    float64\n",
            " 20  V21     569 non-null    float64\n",
            " 21  V22     569 non-null    float64\n",
            " 22  V23     569 non-null    float64\n",
            " 23  V24     569 non-null    float64\n",
            " 24  V25     569 non-null    float64\n",
            " 25  V26     569 non-null    float64\n",
            " 26  V27     569 non-null    float64\n",
            " 27  V28     569 non-null    float64\n",
            " 28  V29     569 non-null    float64\n",
            " 29  V30     569 non-null    float64\n",
            " 30  Class   569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcTA-Dl-_b6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebce3f57-cfff-4955-86e2-c4691a533acc"
      },
      "source": [
        "cancer['Class'].value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "2    212\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMltACB-1vA"
      },
      "source": [
        "X = cancer.drop(['Class'],axis=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOY8H1rt-9PY"
      },
      "source": [
        "y = cancer['Class']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train And Test Splitting"
      ],
      "metadata": {
        "id": "Bp8-1GqhhoKG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEmNqp-7Aufj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84db056d-edb0-47ac-a790-5999210756b2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 30) (114, 30) (455,) (114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models"
      ],
      "metadata": {
        "id": "dqTAN5r-ibbO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm5UnvsQDAgz"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from xgboost import  XGBClassifier \n",
        "\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoXU26qFDIfa"
      },
      "source": [
        "Model_list = [LogisticRegression(),KNeighborsClassifier(),SVC(),DecisionTreeClassifier()]\n",
        "\n",
        "NB_Model_list = [GaussianNB(),MultinomialNB(),ComplementNB(),BernoulliNB()]\n",
        "\n",
        "ensemble_Model_list = [BaggingClassifier(),GradientBoostingClassifier(),AdaBoostClassifier(),RandomForestClassifier(),ExtraTreesClassifier()]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0vINm9UEGEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b867c9-123c-44aa-8a68-1bb25dbd0554"
      },
      "source": [
        "for mod in range(len(Model_list)):\n",
        "  model = Model_list[mod]\n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  print(\"Model Used : \",model)\n",
        "  print(\"=======================================================================\")\n",
        "  print(\"Metrics on Train samples\")\n",
        "  print(\"============================================================== \")\n",
        "  print(\"confusion_matrix: \\n\",confusion_matrix(y_train,y_train_pred))\n",
        "  print(\"classification_report: \\n\",classification_report(y_train,y_train_pred))\n",
        "  print(\"============================================================== \")\n",
        "\n",
        "  y_test_pred = model.predict(X_test)\n",
        "\n",
        "  print(\"Metrics on Test samples \")\n",
        "  print(\"============================================================== \")\n",
        "  print(\"confusion_matrix: \\n\",confusion_matrix(y_test,y_test_pred))\n",
        "  print(\"classification_report: \\n\",classification_report(y_test,y_test_pred))\n",
        "  print(\"============================================================== \")\n",
        "  print(\"=======================================================================\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Used :  LogisticRegression()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[278   8]\n",
            " [ 15 154]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.97      0.96       286\n",
            "           2       0.95      0.91      0.93       169\n",
            "\n",
            "    accuracy                           0.95       455\n",
            "   macro avg       0.95      0.94      0.95       455\n",
            "weighted avg       0.95      0.95      0.95       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[70  1]\n",
            " [ 3 40]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.99      0.97        71\n",
            "           2       0.98      0.93      0.95        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  KNeighborsClassifier()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[281   5]\n",
            " [ 22 147]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.98      0.95       286\n",
            "           2       0.97      0.87      0.92       169\n",
            "\n",
            "    accuracy                           0.94       455\n",
            "   macro avg       0.95      0.93      0.94       455\n",
            "weighted avg       0.94      0.94      0.94       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[71  0]\n",
            " [ 5 38]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.97        71\n",
            "           2       1.00      0.88      0.94        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.94      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  SVC()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[281   5]\n",
            " [ 34 135]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.98      0.94       286\n",
            "           2       0.96      0.80      0.87       169\n",
            "\n",
            "    accuracy                           0.91       455\n",
            "   macro avg       0.93      0.89      0.90       455\n",
            "weighted avg       0.92      0.91      0.91       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[71  0]\n",
            " [ 6 37]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        71\n",
            "           2       1.00      0.86      0.92        43\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  DecisionTreeClassifier()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [  0 169]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00       286\n",
            "           2       1.00      1.00      1.00       169\n",
            "\n",
            "    accuracy                           1.00       455\n",
            "   macro avg       1.00      1.00      1.00       455\n",
            "weighted avg       1.00      1.00      1.00       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[68  3]\n",
            " [ 4 39]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.94      0.96      0.95        71\n",
            "           2       0.93      0.91      0.92        43\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.94      0.93      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp687IFuHSHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdcf9a9c-fb8d-489e-a8f3-fa04e06ad885"
      },
      "source": [
        "for mod in range(len(NB_Model_list)):\n",
        "  model = NB_Model_list[mod]\n",
        "  \n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  print(\"Model Used : \",model)\n",
        "  print(\"=======================================================================\")\n",
        "  print(\"Metrics on Train samples\")\n",
        "  print(\"============================================================== \")\n",
        "  print(\"confusion_matrix: \\n\",confusion_matrix(y_train,y_train_pred))\n",
        "  print(\"classification_report: \\n\",classification_report(y_train,y_train_pred))\n",
        "  print(\"============================================================== \")\n",
        "\n",
        "  y_test_pred = model.predict(X_test)\n",
        "\n",
        "  print(\"Metrics on Test samples \")\n",
        "  print(\"============================================================== \")\n",
        "  print(\"confusion_matrix: \\n\",confusion_matrix(y_test,y_test_pred))\n",
        "  print(\"classification_report: \\n\",classification_report(y_test,y_test_pred))\n",
        "  print(\"============================================================== \")\n",
        "  print(\"=======================================================================\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Used :  GaussianNB()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[277   9]\n",
            " [ 20 149]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.97      0.95       286\n",
            "           2       0.94      0.88      0.91       169\n",
            "\n",
            "    accuracy                           0.94       455\n",
            "   macro avg       0.94      0.93      0.93       455\n",
            "weighted avg       0.94      0.94      0.94       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[71  0]\n",
            " [ 3 40]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      1.00      0.98        71\n",
            "           2       1.00      0.93      0.96        43\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.98      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  MultinomialNB()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[276  10]\n",
            " [ 42 127]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      0.97      0.91       286\n",
            "           2       0.93      0.75      0.83       169\n",
            "\n",
            "    accuracy                           0.89       455\n",
            "   macro avg       0.90      0.86      0.87       455\n",
            "weighted avg       0.89      0.89      0.88       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[71  0]\n",
            " [ 7 36]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      1.00      0.95        71\n",
            "           2       1.00      0.84      0.91        43\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.96      0.92      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  ComplementNB()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[275  11]\n",
            " [ 42 127]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      0.96      0.91       286\n",
            "           2       0.92      0.75      0.83       169\n",
            "\n",
            "    accuracy                           0.88       455\n",
            "   macro avg       0.89      0.86      0.87       455\n",
            "weighted avg       0.89      0.88      0.88       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[71  0]\n",
            " [ 7 36]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      1.00      0.95        71\n",
            "           2       1.00      0.84      0.91        43\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.96      0.92      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  BernoulliNB()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [169   0]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      1.00      0.77       286\n",
            "           2       0.00      0.00      0.00       169\n",
            "\n",
            "    accuracy                           0.63       455\n",
            "   macro avg       0.31      0.50      0.39       455\n",
            "weighted avg       0.40      0.63      0.49       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[71  0]\n",
            " [43  0]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.62      1.00      0.77        71\n",
            "           2       0.00      0.00      0.00        43\n",
            "\n",
            "    accuracy                           0.62       114\n",
            "   macro avg       0.31      0.50      0.38       114\n",
            "weighted avg       0.39      0.62      0.48       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpM7l_ZKHsww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9d828a-89bb-4013-dcfd-b9810d3a3284"
      },
      "source": [
        "for mod in range(len(ensemble_Model_list)):\n",
        "  model = ensemble_Model_list[mod]\n",
        "  \n",
        "  \n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  print(\"Model Used : \",model)\n",
        "  print(\"=======================================================================\")\n",
        "  print(\"Metrics on Train samples\")\n",
        "  print(\"============================================================== \")\n",
        "  print(\"confusion_matrix: \\n\",confusion_matrix(y_train,y_train_pred))\n",
        "  print(\"classification_report: \\n\",classification_report(y_train,y_train_pred))\n",
        "  print(\"============================================================== \")\n",
        "\n",
        "  y_test_pred = model.predict(X_test)\n",
        "\n",
        "  print(\"Metrics on Test samples \")\n",
        "  print(\"============================================================== \")\n",
        "  print(\"confusion_matrix: \\n\",confusion_matrix(y_test,y_test_pred))\n",
        "  print(\"classification_report: \\n\",classification_report(y_test,y_test_pred))\n",
        "  print(\"============================================================== \")\n",
        "  print(\"=======================================================================\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Used :  BaggingClassifier()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [  3 166]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      1.00      0.99       286\n",
            "           2       1.00      0.98      0.99       169\n",
            "\n",
            "    accuracy                           0.99       455\n",
            "   macro avg       0.99      0.99      0.99       455\n",
            "weighted avg       0.99      0.99      0.99       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[69  2]\n",
            " [ 3 40]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.97      0.97        71\n",
            "           2       0.95      0.93      0.94        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  GradientBoostingClassifier()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [  0 169]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00       286\n",
            "           2       1.00      1.00      1.00       169\n",
            "\n",
            "    accuracy                           1.00       455\n",
            "   macro avg       1.00      1.00      1.00       455\n",
            "weighted avg       1.00      1.00      1.00       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[69  2]\n",
            " [ 3 40]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.97      0.97        71\n",
            "           2       0.95      0.93      0.94        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  AdaBoostClassifier()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [  0 169]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00       286\n",
            "           2       1.00      1.00      1.00       169\n",
            "\n",
            "    accuracy                           1.00       455\n",
            "   macro avg       1.00      1.00      1.00       455\n",
            "weighted avg       1.00      1.00      1.00       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[70  1]\n",
            " [ 2 41]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.99      0.98        71\n",
            "           2       0.98      0.95      0.96        43\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  RandomForestClassifier()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [  0 169]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00       286\n",
            "           2       1.00      1.00      1.00       169\n",
            "\n",
            "    accuracy                           1.00       455\n",
            "   macro avg       1.00      1.00      1.00       455\n",
            "weighted avg       1.00      1.00      1.00       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[69  2]\n",
            " [ 3 40]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.97      0.97        71\n",
            "           2       0.95      0.93      0.94        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n",
            "Model Used :  ExtraTreesClassifier()\n",
            "=======================================================================\n",
            "Metrics on Train samples\n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[286   0]\n",
            " [  0 169]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00       286\n",
            "           2       1.00      1.00      1.00       169\n",
            "\n",
            "    accuracy                           1.00       455\n",
            "   macro avg       1.00      1.00      1.00       455\n",
            "weighted avg       1.00      1.00      1.00       455\n",
            "\n",
            "============================================================== \n",
            "Metrics on Test samples \n",
            "============================================================== \n",
            "confusion_matrix: \n",
            " [[70  1]\n",
            " [ 2 41]]\n",
            "classification_report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.99      0.98        71\n",
            "           2       0.98      0.95      0.96        43\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n",
            "============================================================== \n",
            "=======================================================================\n"
          ]
        }
      ]
    }
  ]
}